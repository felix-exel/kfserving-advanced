{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Notebook uses a Session Event Dataset from E-Commerce Website(https://www.kaggle.com/mkechinov/ecommerce-behavior-data-from-multi-category-store and https://rees46.com/) to build a Session Based Recommender. An LSTM-based Model will be created and the Metadata will be tracked by MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autopep8         1.5.4\n",
      "tensorflow       2.4.0\n",
      "tensorflow_hub   0.9.0\n",
      "numpy            1.19.5\n",
      "tensorflow.keras 2.4.0\n",
      "pandas           1.0.5\n",
      "json             2.0.9\n",
      "CPython 3.7.4\n",
      "IPython 7.8.0\n"
     ]
    }
   ],
   "source": [
    "#import mlflow\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow_hub as hub\n",
    "from itertools import product\n",
    "\n",
    "# enable gpu growth if gpu is available\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "# Enable XLA.\n",
    "tf.config.optimizer.set_jit(True)\n",
    "\n",
    "%load_ext watermark\n",
    "%watermark -v -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Registry and Tracking URI for MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this registry uri when mlflow is created by docker container with a mysql db backend\n",
    "#registry_uri = os.path.expandvars('mysql+pymysql://${MYSQL_USER}:${MYSQL_PASSWORD}@localhost:3306/${MYSQL_DATABASE}')\n",
    "\n",
    "# Use this registry uri when mlflow is running locally by the command:\n",
    "# \"mlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./mlruns --host 0.0.0.0\"\n",
    "registry_uri = 'sqlite:///mlflow.db'\n",
    "\n",
    "tracking_uri = 'http://localhost:5000'\n",
    "\n",
    "mlflow.tracking.set_registry_uri(registry_uri)\n",
    "mlflow.tracking.set_tracking_uri(tracking_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data is taken from https://www.kaggle.com/mkechinov/ecommerce-behavior-data-from-multi-category-store and https://rees46.com/\n",
    "## Each record/line in the file has the following fields:\n",
    "1. event_time: When did the event happened (UTC)\n",
    "2. event_type: Event type: one of [view, cart, remove_from_cart, purchase] \n",
    "3. product_id\n",
    "4. category_id\n",
    "5. category_code: Category meaningful name (if present)\n",
    "6. brand: Brand name in lower case (if present)\n",
    "7. price\n",
    "8. user_id: Permanent user ID\n",
    "9. user_session: User session ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 284.77105468660056\n",
      "Std: 349.4674023158121\n",
      "Sessions: (61296,)\n",
      "Unique Products: (38515,)\n",
      "Unique category_code: (134,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding_0</th>\n",
       "      <th>embedding_1</th>\n",
       "      <th>embedding_2</th>\n",
       "      <th>embedding_3</th>\n",
       "      <th>embedding_4</th>\n",
       "      <th>embedding_5</th>\n",
       "      <th>embedding_6</th>\n",
       "      <th>embedding_7</th>\n",
       "      <th>embedding_8</th>\n",
       "      <th>embedding_9</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_45</th>\n",
       "      <th>embedding_46</th>\n",
       "      <th>embedding_47</th>\n",
       "      <th>embedding_48</th>\n",
       "      <th>embedding_49</th>\n",
       "      <th>price_standardized</th>\n",
       "      <th>user_session</th>\n",
       "      <th>Product</th>\n",
       "      <th>product_id</th>\n",
       "      <th>category_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.047610</td>\n",
       "      <td>-0.125734</td>\n",
       "      <td>-0.053261</td>\n",
       "      <td>0.196848</td>\n",
       "      <td>-0.016433</td>\n",
       "      <td>0.049773</td>\n",
       "      <td>0.012852</td>\n",
       "      <td>0.263229</td>\n",
       "      <td>-0.195415</td>\n",
       "      <td>0.327227</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.214412</td>\n",
       "      <td>0.090539</td>\n",
       "      <td>0.104421</td>\n",
       "      <td>0.061444</td>\n",
       "      <td>-0.008996</td>\n",
       "      <td>-0.373028</td>\n",
       "      <td>0000afb3-2d30-4b52-84ec-07c6617efd37</td>\n",
       "      <td>light</td>\n",
       "      <td>1004838</td>\n",
       "      <td>construction.tools.light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.047610</td>\n",
       "      <td>-0.125734</td>\n",
       "      <td>-0.053261</td>\n",
       "      <td>0.196848</td>\n",
       "      <td>-0.016433</td>\n",
       "      <td>0.049773</td>\n",
       "      <td>0.012852</td>\n",
       "      <td>0.263229</td>\n",
       "      <td>-0.195415</td>\n",
       "      <td>0.327227</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.214412</td>\n",
       "      <td>0.090539</td>\n",
       "      <td>0.104421</td>\n",
       "      <td>0.061444</td>\n",
       "      <td>-0.008996</td>\n",
       "      <td>-0.373028</td>\n",
       "      <td>0000afb3-2d30-4b52-84ec-07c6617efd37</td>\n",
       "      <td>light</td>\n",
       "      <td>1004838</td>\n",
       "      <td>construction.tools.light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.047610</td>\n",
       "      <td>-0.125734</td>\n",
       "      <td>-0.053261</td>\n",
       "      <td>0.196848</td>\n",
       "      <td>-0.016433</td>\n",
       "      <td>0.049773</td>\n",
       "      <td>0.012852</td>\n",
       "      <td>0.263229</td>\n",
       "      <td>-0.195415</td>\n",
       "      <td>0.327227</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.214412</td>\n",
       "      <td>0.090539</td>\n",
       "      <td>0.104421</td>\n",
       "      <td>0.061444</td>\n",
       "      <td>-0.008996</td>\n",
       "      <td>0.068930</td>\n",
       "      <td>0000b83c-9b26-4881-8bca-e20d460f4194</td>\n",
       "      <td>light</td>\n",
       "      <td>1005252</td>\n",
       "      <td>construction.tools.light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.047610</td>\n",
       "      <td>-0.125734</td>\n",
       "      <td>-0.053261</td>\n",
       "      <td>0.196848</td>\n",
       "      <td>-0.016433</td>\n",
       "      <td>0.049773</td>\n",
       "      <td>0.012852</td>\n",
       "      <td>0.263229</td>\n",
       "      <td>-0.195415</td>\n",
       "      <td>0.327227</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.214412</td>\n",
       "      <td>0.090539</td>\n",
       "      <td>0.104421</td>\n",
       "      <td>0.061444</td>\n",
       "      <td>-0.008996</td>\n",
       "      <td>0.289895</td>\n",
       "      <td>0000b83c-9b26-4881-8bca-e20d460f4194</td>\n",
       "      <td>light</td>\n",
       "      <td>1004503</td>\n",
       "      <td>construction.tools.light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.047610</td>\n",
       "      <td>-0.125734</td>\n",
       "      <td>-0.053261</td>\n",
       "      <td>0.196848</td>\n",
       "      <td>-0.016433</td>\n",
       "      <td>0.049773</td>\n",
       "      <td>0.012852</td>\n",
       "      <td>0.263229</td>\n",
       "      <td>-0.195415</td>\n",
       "      <td>0.327227</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.214412</td>\n",
       "      <td>0.090539</td>\n",
       "      <td>0.104421</td>\n",
       "      <td>0.061444</td>\n",
       "      <td>-0.008996</td>\n",
       "      <td>-0.291904</td>\n",
       "      <td>0000f7c4-8836-4507-82a1-8a10de3fb1b2</td>\n",
       "      <td>light</td>\n",
       "      <td>1005191</td>\n",
       "      <td>construction.tools.light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369299</th>\n",
       "      <td>0.174397</td>\n",
       "      <td>-0.204014</td>\n",
       "      <td>-0.175919</td>\n",
       "      <td>0.105906</td>\n",
       "      <td>-0.205940</td>\n",
       "      <td>-0.210022</td>\n",
       "      <td>0.224095</td>\n",
       "      <td>0.210598</td>\n",
       "      <td>-0.162613</td>\n",
       "      <td>0.150693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071817</td>\n",
       "      <td>-0.129293</td>\n",
       "      <td>-0.176801</td>\n",
       "      <td>0.100340</td>\n",
       "      <td>0.119850</td>\n",
       "      <td>-0.630791</td>\n",
       "      <td>fffdfd5e-126c-409f-9c16-8224f22cb60b</td>\n",
       "      <td>cooler</td>\n",
       "      <td>4400467</td>\n",
       "      <td>computers.components.cooler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369300</th>\n",
       "      <td>0.047610</td>\n",
       "      <td>-0.125734</td>\n",
       "      <td>-0.053261</td>\n",
       "      <td>0.196848</td>\n",
       "      <td>-0.016433</td>\n",
       "      <td>0.049773</td>\n",
       "      <td>0.012852</td>\n",
       "      <td>0.263229</td>\n",
       "      <td>-0.195415</td>\n",
       "      <td>0.327227</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.214412</td>\n",
       "      <td>0.090539</td>\n",
       "      <td>0.104421</td>\n",
       "      <td>0.061444</td>\n",
       "      <td>-0.008996</td>\n",
       "      <td>-0.511696</td>\n",
       "      <td>fffe34dd-9537-4991-9f12-d81f1dda91cb</td>\n",
       "      <td>light</td>\n",
       "      <td>1004903</td>\n",
       "      <td>construction.tools.light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369301</th>\n",
       "      <td>0.047610</td>\n",
       "      <td>-0.125734</td>\n",
       "      <td>-0.053261</td>\n",
       "      <td>0.196848</td>\n",
       "      <td>-0.016433</td>\n",
       "      <td>0.049773</td>\n",
       "      <td>0.012852</td>\n",
       "      <td>0.263229</td>\n",
       "      <td>-0.195415</td>\n",
       "      <td>0.327227</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.214412</td>\n",
       "      <td>0.090539</td>\n",
       "      <td>0.104421</td>\n",
       "      <td>0.061444</td>\n",
       "      <td>-0.008996</td>\n",
       "      <td>-0.511696</td>\n",
       "      <td>fffe34dd-9537-4991-9f12-d81f1dda91cb</td>\n",
       "      <td>light</td>\n",
       "      <td>1004903</td>\n",
       "      <td>construction.tools.light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369302</th>\n",
       "      <td>0.047610</td>\n",
       "      <td>-0.125734</td>\n",
       "      <td>-0.053261</td>\n",
       "      <td>0.196848</td>\n",
       "      <td>-0.016433</td>\n",
       "      <td>0.049773</td>\n",
       "      <td>0.012852</td>\n",
       "      <td>0.263229</td>\n",
       "      <td>-0.195415</td>\n",
       "      <td>0.327227</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.214412</td>\n",
       "      <td>0.090539</td>\n",
       "      <td>0.104421</td>\n",
       "      <td>0.061444</td>\n",
       "      <td>-0.008996</td>\n",
       "      <td>-0.459760</td>\n",
       "      <td>fffe34dd-9537-4991-9f12-d81f1dda91cb</td>\n",
       "      <td>light</td>\n",
       "      <td>1004856</td>\n",
       "      <td>construction.tools.light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369303</th>\n",
       "      <td>0.047610</td>\n",
       "      <td>-0.125734</td>\n",
       "      <td>-0.053261</td>\n",
       "      <td>0.196848</td>\n",
       "      <td>-0.016433</td>\n",
       "      <td>0.049773</td>\n",
       "      <td>0.012852</td>\n",
       "      <td>0.263229</td>\n",
       "      <td>-0.195415</td>\n",
       "      <td>0.327227</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.214412</td>\n",
       "      <td>0.090539</td>\n",
       "      <td>0.104421</td>\n",
       "      <td>0.061444</td>\n",
       "      <td>-0.008996</td>\n",
       "      <td>-0.459760</td>\n",
       "      <td>fffe34dd-9537-4991-9f12-d81f1dda91cb</td>\n",
       "      <td>light</td>\n",
       "      <td>1004856</td>\n",
       "      <td>construction.tools.light</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>369304 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        embedding_0  embedding_1  embedding_2  embedding_3  embedding_4  \\\n",
       "0          0.047610    -0.125734    -0.053261     0.196848    -0.016433   \n",
       "1          0.047610    -0.125734    -0.053261     0.196848    -0.016433   \n",
       "2          0.047610    -0.125734    -0.053261     0.196848    -0.016433   \n",
       "3          0.047610    -0.125734    -0.053261     0.196848    -0.016433   \n",
       "4          0.047610    -0.125734    -0.053261     0.196848    -0.016433   \n",
       "...             ...          ...          ...          ...          ...   \n",
       "369299     0.174397    -0.204014    -0.175919     0.105906    -0.205940   \n",
       "369300     0.047610    -0.125734    -0.053261     0.196848    -0.016433   \n",
       "369301     0.047610    -0.125734    -0.053261     0.196848    -0.016433   \n",
       "369302     0.047610    -0.125734    -0.053261     0.196848    -0.016433   \n",
       "369303     0.047610    -0.125734    -0.053261     0.196848    -0.016433   \n",
       "\n",
       "        embedding_5  embedding_6  embedding_7  embedding_8  embedding_9  ...  \\\n",
       "0          0.049773     0.012852     0.263229    -0.195415     0.327227  ...   \n",
       "1          0.049773     0.012852     0.263229    -0.195415     0.327227  ...   \n",
       "2          0.049773     0.012852     0.263229    -0.195415     0.327227  ...   \n",
       "3          0.049773     0.012852     0.263229    -0.195415     0.327227  ...   \n",
       "4          0.049773     0.012852     0.263229    -0.195415     0.327227  ...   \n",
       "...             ...          ...          ...          ...          ...  ...   \n",
       "369299    -0.210022     0.224095     0.210598    -0.162613     0.150693  ...   \n",
       "369300     0.049773     0.012852     0.263229    -0.195415     0.327227  ...   \n",
       "369301     0.049773     0.012852     0.263229    -0.195415     0.327227  ...   \n",
       "369302     0.049773     0.012852     0.263229    -0.195415     0.327227  ...   \n",
       "369303     0.049773     0.012852     0.263229    -0.195415     0.327227  ...   \n",
       "\n",
       "        embedding_45  embedding_46  embedding_47  embedding_48  embedding_49  \\\n",
       "0          -0.214412      0.090539      0.104421      0.061444     -0.008996   \n",
       "1          -0.214412      0.090539      0.104421      0.061444     -0.008996   \n",
       "2          -0.214412      0.090539      0.104421      0.061444     -0.008996   \n",
       "3          -0.214412      0.090539      0.104421      0.061444     -0.008996   \n",
       "4          -0.214412      0.090539      0.104421      0.061444     -0.008996   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "369299      0.071817     -0.129293     -0.176801      0.100340      0.119850   \n",
       "369300     -0.214412      0.090539      0.104421      0.061444     -0.008996   \n",
       "369301     -0.214412      0.090539      0.104421      0.061444     -0.008996   \n",
       "369302     -0.214412      0.090539      0.104421      0.061444     -0.008996   \n",
       "369303     -0.214412      0.090539      0.104421      0.061444     -0.008996   \n",
       "\n",
       "        price_standardized                          user_session  Product  \\\n",
       "0                -0.373028  0000afb3-2d30-4b52-84ec-07c6617efd37    light   \n",
       "1                -0.373028  0000afb3-2d30-4b52-84ec-07c6617efd37    light   \n",
       "2                 0.068930  0000b83c-9b26-4881-8bca-e20d460f4194    light   \n",
       "3                 0.289895  0000b83c-9b26-4881-8bca-e20d460f4194    light   \n",
       "4                -0.291904  0000f7c4-8836-4507-82a1-8a10de3fb1b2    light   \n",
       "...                    ...                                   ...      ...   \n",
       "369299           -0.630791  fffdfd5e-126c-409f-9c16-8224f22cb60b   cooler   \n",
       "369300           -0.511696  fffe34dd-9537-4991-9f12-d81f1dda91cb    light   \n",
       "369301           -0.511696  fffe34dd-9537-4991-9f12-d81f1dda91cb    light   \n",
       "369302           -0.459760  fffe34dd-9537-4991-9f12-d81f1dda91cb    light   \n",
       "369303           -0.459760  fffe34dd-9537-4991-9f12-d81f1dda91cb    light   \n",
       "\n",
       "        product_id                category_code  \n",
       "0          1004838     construction.tools.light  \n",
       "1          1004838     construction.tools.light  \n",
       "2          1005252     construction.tools.light  \n",
       "3          1004503     construction.tools.light  \n",
       "4          1005191     construction.tools.light  \n",
       "...            ...                          ...  \n",
       "369299     4400467  computers.components.cooler  \n",
       "369300     1004903     construction.tools.light  \n",
       "369301     1004903     construction.tools.light  \n",
       "369302     1004856     construction.tools.light  \n",
       "369303     1004856     construction.tools.light  \n",
       "\n",
       "[369304 rows x 55 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read first 500.000 Rows\n",
    "for chunk in pd.read_table(\"2019-Dec.csv\",\n",
    "                           sep=\",\", header=0,\n",
    "                           infer_datetime_format=True, low_memory=False, chunksize=500000):\n",
    "    # Filter out other event types than 'view'\n",
    "    chunk = chunk[chunk['event_type'] == 'view']\n",
    "    # Filter out missing 'category_code' rows\n",
    "    chunk = chunk[chunk['category_code'].isna() == False]\n",
    "    chunk.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Filter out all Sessions of length 1\n",
    "    count_sessions = chunk.groupby('user_session').count()\n",
    "    window_length = count_sessions.max()[0]\n",
    "    unique_sessions = [count_sessions.index[i] for i in range(\n",
    "        count_sessions.shape[0]) if count_sessions.iloc[i, 0] == 1]\n",
    "    chunk = chunk[~chunk['user_session'].isin(unique_sessions)]\n",
    "    chunk.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Text embedding based on https://tfhub.dev/google/nnlm-en-dim50/2\n",
    "    last_category = []\n",
    "    for i, el in enumerate(chunk['category_code']):\n",
    "        last_category.append(el.split('.')[-1])\n",
    "    chunk['Product'] = last_category\n",
    "    embed = hub.load(\"https://tfhub.dev/google/nnlm-en-dim50/2\")\n",
    "    embeddings = embed(chunk['Product'].tolist())\n",
    "    for dim in range(embeddings.shape[1]):\n",
    "        chunk['embedding_'+str(dim)] = embeddings[:, dim]\n",
    "\n",
    "    # Standardization\n",
    "    mean = chunk['price'].mean(axis=0)\n",
    "    print('Mean:', mean)\n",
    "    std = chunk['price'].std(axis=0)\n",
    "    print('Std:', std)\n",
    "    chunk['price_standardized'] = (chunk['price'] - mean) / std\n",
    "\n",
    "    chunk.sort_values(by=['user_session', 'event_time'], inplace=True)\n",
    "    chunk['price_standardized'] = chunk['price_standardized'].astype('float32')\n",
    "    chunk['product_id'] = chunk['product_id'].astype('int32')\n",
    "    chunk.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    print('Sessions:', pd.unique(chunk['user_session']).shape)\n",
    "    print('Unique Products:', pd.unique(chunk['product_id']).shape)\n",
    "    print('Unique category_code:', pd.unique(chunk['category_code']).shape)\n",
    "\n",
    "    columns = ['embedding_'+str(i) for i in range(embeddings.shape[1])]\n",
    "    columns.append('price_standardized')\n",
    "    columns.append('user_session')\n",
    "    columns.append('Product')\n",
    "    columns.append('product_id')\n",
    "    columns.append('category_code')\n",
    "\n",
    "    df = chunk[columns]\n",
    "    break\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Rows with equal or less than 6 Product Occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([  1000978,   1002102,   1002367,   1002876,   1002877,   1002996,\n",
       "              1003001,   1003014,   1003048,   1003050,\n",
       "            ...\n",
       "            100028638, 100028646, 100028653, 100028659, 100028661, 100028663,\n",
       "            100028668, 100028717, 100028774, 100028794],\n",
       "           dtype='int64', name='product_id', length=29774)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_product_id_mapped = df.groupby('product_id').count()\n",
    "products_to_delete = count_product_id_mapped.loc[count_product_id_mapped['embedding_0'] <= 6].index\n",
    "products_to_delete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slice Sessions from the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_sessions = []\n",
    "list_last_clicked = []\n",
    "current_id = df.loc[0, 'user_session']\n",
    "current_index = 0\n",
    "\n",
    "columns = ['embedding_'+str(i) for i in range(embeddings.shape[1])]\n",
    "columns.append('price_standardized')\n",
    "columns.insert(0, 'product_id')\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    if df.loc[i, 'user_session'] != current_id:\n",
    "        list_sessions.append(df.loc[current_index:i-2, columns])\n",
    "        list_last_clicked.append(df.loc[i-1, 'product_id'])\n",
    "        current_id = df.loc[i, 'user_session']\n",
    "        current_index = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Sessions with Length larger than 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61295\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "44551"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(list_sessions))\n",
    "list_sessions_filtered = []\n",
    "list_last_clicked_filtered = []\n",
    "\n",
    "for index, session in enumerate(list_sessions):\n",
    "    if not (session.shape[0] > 30):\n",
    "        if not (session['product_id'].isin(products_to_delete).any()):\n",
    "            list_sessions_filtered.append(session)\n",
    "            list_last_clicked_filtered.append(list_last_clicked[index])\n",
    "            \n",
    "len(list_sessions_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slice Sessions if label and last product from session is the same\n",
    "Example:\n",
    "- From: session: [ 1506  1506 11410 11410  2826  2826], ground truth: 2826\n",
    "- To: session: [ 1506  1506 11410 11410], ground truth: 2826"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length before 44551\n",
      "Length after 30941\n"
     ]
    }
   ],
   "source": [
    "print(\"Length before\", len(list_sessions_filtered))\n",
    "list_sessions_processed = []\n",
    "list_last_clicked_processed = []\n",
    "\n",
    "for i, session in enumerate(list_sessions_filtered):\n",
    "    if session['product_id'].values[-1] == list_last_clicked_filtered[i]:\n",
    "        mask = session['product_id'].values == list_last_clicked_filtered[i]\n",
    "        if session[~mask].shape[0] > 0:\n",
    "            list_sessions_processed.append(session[~mask])\n",
    "            list_last_clicked_processed.append(list_last_clicked_filtered[i])\n",
    "    else:\n",
    "        list_sessions_processed.append(session)\n",
    "        list_last_clicked_processed.append(list_last_clicked_filtered[i])\n",
    "\n",
    "print(\"Length after\", len(list_sessions_processed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Item IDs starting from value 1 for Embeddings and One Hot Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique Items: 9494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "products = pd.DataFrame()\n",
    "\n",
    "for index, session in enumerate(list_sessions_processed):\n",
    "    products = pd.concat([products, session['product_id']], ignore_index=True)\n",
    "\n",
    "products = pd.concat([products, pd.DataFrame(\n",
    "    list_last_clicked_processed)], ignore_index=True)\n",
    "\n",
    "unique_items = pd.unique(products[0])\n",
    "\n",
    "print('Number of unique Items:', unique_items.shape[0])\n",
    "dict_items = dict(\n",
    "    zip(unique_items, [i+1 for i in range(unique_items.shape[0])]))\n",
    "\n",
    "for index, session in enumerate(list_sessions_processed):\n",
    "    session['product_id'] = session['product_id'].map(dict_items)\n",
    "\n",
    "list_last_clicked_processed = pd.DataFrame(list_last_clicked_processed)[\n",
    "    0].map(dict_items).tolist()\n",
    "\n",
    "d = pd.DataFrame.from_records(data=list(dict_items.items()), columns=[\n",
    "    'Item_ID', 'Mapped_ID'])\n",
    "# map product_id to category_code\n",
    "d['category_code'] = [df[df['product_id'] == i]\n",
    "                      ['category_code'].values[0] for i in d['Item_ID']]\n",
    "d.to_csv('ID_Mapping.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_output_features 9494\n",
      "n_unique_input_ids 7030\n",
      "window_length 30\n",
      "n_input_features 52\n"
     ]
    }
   ],
   "source": [
    "# Pad all Sessions with 0. Embedding Layer and LSTM will use Masking to ignore zeros.\n",
    "list_sessions_padded = []\n",
    "window_length = 30\n",
    "\n",
    "for df in list_sessions_processed:\n",
    "    np_array = df.values\n",
    "    result = np.zeros((window_length, np_array.shape[1]), dtype=np.float32)\n",
    "\n",
    "    result[:np_array.shape[0], :np_array.shape[1]] = np_array\n",
    "    list_sessions_padded.append(result)\n",
    "\n",
    "\n",
    "# Save the results, because the slicing can take some time\n",
    "np.save('list_sessions_padded.npy', list_sessions_padded)\n",
    "np.save('list_last_clicked.npy', list_last_clicked_processed)\n",
    "\n",
    "sessions_padded = np.array(list_sessions_padded)\n",
    "last_clicked = np.array(list_last_clicked_processed)\n",
    "\n",
    "n_output_features = int(last_clicked.max())\n",
    "n_unique_input_ids = int(sessions_padded[:, :, 0].max())\n",
    "window_length = sessions_padded.shape[1]\n",
    "n_input_features = sessions_padded.shape[2]\n",
    "print(\"n_output_features\", n_output_features)\n",
    "print(\"n_unique_input_ids\", n_unique_input_ids)\n",
    "print(\"window_length\", window_length)\n",
    "print(\"n_input_features\", n_input_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training: Start here if the preprocessing was already executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30941, 30, 52)\n",
      "(30941,)\n"
     ]
    }
   ],
   "source": [
    "sessions_padded = np.load('list_sessions_padded.npy')\n",
    "print(sessions_padded.shape)\n",
    "last_clicked = np.load('list_last_clicked.npy')\n",
    "print(last_clicked.shape)\n",
    "n_output_features = int(last_clicked.max())\n",
    "n_unique_input_ids = int(sessions_padded[:, :, 0].max())\n",
    "window_length = sessions_padded.shape[1]\n",
    "n_input_features = sessions_padded.shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Hyperparameter\n",
    "Dictionary with different hyperparameters to train on.\n",
    "MLflow will track those in a database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'hidden_layer_size': 5,\n",
       "  'batch_size': 32,\n",
       "  'embedding_dim': 200,\n",
       "  'window_length': 30,\n",
       "  'dropout_fc': 0.0,\n",
       "  'n_output_features': 9494,\n",
       "  'n_input_features': 52}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_dic = {'hidden_layer_size': [5],\n",
    "                   'batch_size': [32],\n",
    "                   'embedding_dim': [200],\n",
    "                   'window_length': [window_length],\n",
    "                   'dropout_fc': [0.0],  # 0.2\n",
    "                   'n_output_features': [n_output_features],\n",
    "                   'n_input_features': [n_input_features]}\n",
    "\n",
    "# Cartesian product\n",
    "grid_search_param = [dict(zip(grid_search_dic, v))\n",
    "                     for v in product(*grid_search_dic.values())]\n",
    "grid_search_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Model in functional API\n",
    "2 layer LSTM model for predicting the next clicked product.\n",
    "- Input: x rows (time steps) of Item IDs in a Session. Shape: (batches, window_length, features)\n",
    "- Output: Prediction of the next Clicked Item. Shape: (batches,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_2_layer_model(window_length=50, embedding_dim=200, n_input_features=5, n_unique_input_ids=0,\n",
    "                             n_output_features=3, units_lstm_layer=30, dropout_rate=0.2):\n",
    "    \"\"\"Builds 2 Layer LSTM-based TF Model in functional API.\n",
    "    Args:\n",
    "        window_length: Input Data as Numpy Array, Shape (rows, n_features)\n",
    "        embedding_dim: Number Dimensions of the Embedding Layer.\n",
    "        n_output_features: Number (Classes) of Items.\n",
    "        units_lstm_layer: Number of Neurons for the LSTM Layers.\n",
    "        dropout_rate: Dropout Rate for the last Fully Connected Dense Layer.\n",
    "    Returns:\n",
    "        keras.models.Model\n",
    "    \"\"\"\n",
    "    inputs = keras.layers.Input(\n",
    "        shape=[window_length, n_input_features], dtype=np.float32)\n",
    "\n",
    "    # Embedding Layer\n",
    "    embedding_layer = tf.keras.layers.Embedding(\n",
    "        n_unique_input_ids+1, embedding_dim, input_length=window_length, mask_zero=True)\n",
    "    embeddings = embedding_layer(inputs[:, :, 0])\n",
    "\n",
    "    concat = tf.concat([embeddings, inputs[:, :, 1:]], axis=2)\n",
    "\n",
    "    # LSTM Layer 1\n",
    "    lstm1_output, lstm1_state_h, lstm1_state_c = keras.layers.LSTM(units=units_lstm_layer, return_state=True,\n",
    "                                                                   return_sequences=True)(concat)\n",
    "    lstm1_state = [lstm1_state_h, lstm1_state_c]\n",
    "\n",
    "    # LSTM Layer 2\n",
    "    lstm2_output, lstm2_state_h, lstm2_state_c = keras.layers.LSTM(units=units_lstm_layer, return_state=True,\n",
    "                                                                   return_sequences=True)(lstm1_output,\n",
    "                                                                                          initial_state=lstm1_state)\n",
    "\n",
    "    reshaped = tf.reshape(lstm2_output,\n",
    "                          [-1, window_length * units_lstm_layer])\n",
    "    #concat = tf.concat([lstm2_state_h, lstm2_state_c], axis=1)\n",
    "\n",
    "    # Dropout\n",
    "    dropout = tf.keras.layers.Dropout(dropout_rate)(reshaped)\n",
    "\n",
    "    fc_layer = keras.layers.Dense(n_output_features+1, kernel_initializer='he_normal', dtype=tf.float32)(\n",
    "        dropout)\n",
    "\n",
    "    softmax = tf.keras.layers.Softmax(axis=1)(fc_layer)\n",
    "\n",
    "    model = keras.models.Model(inputs=[inputs],\n",
    "                               outputs=[softmax])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Numpy Array to tf.data.Dataset for better training performance\n",
    "The function will return a zipped tf.data.Dataset with the following Shapes:\n",
    "- x: (batches, window_length, features)\n",
    "- y: (batches,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_tf_data_api(train_data_x, train_data_y, batch_size=64, window_length=50,\n",
    "                         validate=False):\n",
    "    \"\"\"Applies sliding window on the fly by using the TF Data API.\n",
    "    Args:\n",
    "      train_data_x: Input Data as Numpy Array, Shape (rows, n_features)\n",
    "      batch_size: Batch Size.\n",
    "      window_length: Window Length or Window Size.\n",
    "      future_length: Number of time steps that will be predicted in the future.\n",
    "      n_output_features: Number of features that will be predicted.\n",
    "      validate: True if input data is a validation set and does not need to be shuffled\n",
    "      shift: Shifts the Sliding Window by this Parameter.\n",
    "    Returns:\n",
    "      tf.data.Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    X = tf.data.Dataset.from_tensor_slices(train_data_x)\n",
    "    y = tf.data.Dataset.from_tensor_slices(train_data_y)\n",
    "\n",
    "    if not validate:\n",
    "        train_tf_data = tf.data.Dataset.zip((X, y)).cache() \\\n",
    "            .shuffle(buffer_size=200000, reshuffle_each_iteration=True)\\\n",
    "            .batch(batch_size).prefetch(1)\n",
    "        return train_tf_data\n",
    "    else:\n",
    "        return tf.data.Dataset.zip((X, y)).batch(batch_size)\\\n",
    "            .prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom TF Callback to log Metrics by MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MlflowLogging(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()  # handles base args (e.g., dtype)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        for key in keys:\n",
    "            mlflow.log_metric(str(key), logs.get(key), step=epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1435/1435 [==============================] - 75s 49ms/step - loss: 9.3842 - accuracy: 0.0079\n",
      "Epoch 2/50\n",
      "1435/1435 [==============================] - 70s 49ms/step - loss: 8.0967 - accuracy: 0.0150\n",
      "Epoch 3/50\n",
      "1435/1435 [==============================] - 68s 48ms/step - loss: 7.3505 - accuracy: 0.0256\n",
      "Epoch 4/50\n",
      "1435/1435 [==============================] - 68s 48ms/step - loss: 6.7261 - accuracy: 0.0356\n",
      "Epoch 5/50\n",
      "1435/1435 [==============================] - 68s 47ms/step - loss: 6.1909 - accuracy: 0.0529\n",
      "Epoch 6/50\n",
      "1435/1435 [==============================] - 68s 47ms/step - loss: 5.7169 - accuracy: 0.0716\n",
      "Epoch 7/50\n",
      "1435/1435 [==============================] - 68s 48ms/step - loss: 5.3025 - accuracy: 0.0983\n",
      "Epoch 8/50\n",
      "1435/1435 [==============================] - 68s 48ms/step - loss: 4.9508 - accuracy: 0.1271\n",
      "Epoch 9/50\n",
      "1435/1435 [==============================] - 68s 47ms/step - loss: 4.6516 - accuracy: 0.1579\n",
      "Epoch 10/50\n",
      "1435/1435 [==============================] - 70s 49ms/step - loss: 4.3896 - accuracy: 0.1826\n",
      "Epoch 11/50\n",
      "1435/1435 [==============================] - 67s 46ms/step - loss: 4.1459 - accuracy: 0.2147\n",
      "Epoch 12/50\n",
      "1435/1435 [==============================] - 69s 48ms/step - loss: 3.9646 - accuracy: 0.2392\n",
      "Epoch 13/50\n",
      "1435/1435 [==============================] - 71s 49ms/step - loss: 3.7548 - accuracy: 0.2659\n",
      "Epoch 14/50\n",
      "1435/1435 [==============================] - 71s 49ms/step - loss: 3.5716 - accuracy: 0.2909\n",
      "Epoch 15/50\n",
      "1435/1435 [==============================] - 68s 47ms/step - loss: 3.4447 - accuracy: 0.3120\n",
      "Epoch 16/50\n",
      "1435/1435 [==============================] - 70s 49ms/step - loss: 3.3161 - accuracy: 0.3303\n",
      "Epoch 17/50\n",
      "1435/1435 [==============================] - 70s 49ms/step - loss: 3.1803 - accuracy: 0.3537\n",
      "Epoch 18/50\n",
      "1435/1435 [==============================] - 68s 47ms/step - loss: 3.0711 - accuracy: 0.3734\n",
      "Epoch 19/50\n",
      "1435/1435 [==============================] - 70s 49ms/step - loss: 2.9534 - accuracy: 0.3921\n",
      "Epoch 20/50\n",
      "1435/1435 [==============================] - 70s 49ms/step - loss: 2.8504 - accuracy: 0.4083\n",
      "Epoch 21/50\n",
      "1435/1435 [==============================] - 72s 50ms/step - loss: 2.7347 - accuracy: 0.4297\n",
      "Epoch 22/50\n",
      "1435/1435 [==============================] - 71s 50ms/step - loss: 2.6626 - accuracy: 0.4419\n",
      "Epoch 23/50\n",
      "1435/1435 [==============================] - 71s 49ms/step - loss: 2.6041 - accuracy: 0.4541\n",
      "Epoch 24/50\n",
      "1435/1435 [==============================] - 72s 50ms/step - loss: 2.5239 - accuracy: 0.4645\n",
      "Epoch 25/50\n",
      "1435/1435 [==============================] - 71s 50ms/step - loss: 2.4344 - accuracy: 0.4826\n",
      "Epoch 26/50\n",
      "1435/1435 [==============================] - 71s 50ms/step - loss: 2.3862 - accuracy: 0.4907\n",
      "Epoch 27/50\n",
      "1435/1435 [==============================] - 71s 50ms/step - loss: 2.3268 - accuracy: 0.5012\n",
      "Epoch 28/50\n",
      "1435/1435 [==============================] - 69s 48ms/step - loss: 2.2731 - accuracy: 0.5100\n",
      "Epoch 29/50\n",
      "1435/1435 [==============================] - 71s 50ms/step - loss: 2.2402 - accuracy: 0.5209\n",
      "Epoch 30/50\n",
      "1435/1435 [==============================] - 69s 48ms/step - loss: 2.1599 - accuracy: 0.5321\n",
      "Epoch 31/50\n",
      "1435/1435 [==============================] - 72s 50ms/step - loss: 2.1406 - accuracy: 0.5397\n",
      "Epoch 32/50\n",
      "1435/1435 [==============================] - 72s 50ms/step - loss: 2.0723 - accuracy: 0.5494\n",
      "Epoch 33/50\n",
      "1435/1435 [==============================] - 70s 49ms/step - loss: 2.0309 - accuracy: 0.5546\n",
      "Epoch 34/50\n",
      "1435/1435 [==============================] - 70s 49ms/step - loss: 2.0150 - accuracy: 0.5569\n",
      "Epoch 35/50\n",
      "1435/1435 [==============================] - 72s 50ms/step - loss: 1.9645 - accuracy: 0.5650\n",
      "Epoch 36/50\n",
      "1435/1435 [==============================] - 71s 50ms/step - loss: 1.9153 - accuracy: 0.5775\n",
      "Epoch 37/50\n",
      "1435/1435 [==============================] - 72s 50ms/step - loss: 1.9058 - accuracy: 0.5810\n",
      "Epoch 38/50\n",
      "1435/1435 [==============================] - 73s 51ms/step - loss: 1.8599 - accuracy: 0.5873\n",
      "Epoch 39/50\n",
      "1435/1435 [==============================] - 70s 49ms/step - loss: 1.8285 - accuracy: 0.5924\n",
      "Epoch 40/50\n",
      "1435/1435 [==============================] - 72s 50ms/step - loss: 1.8212 - accuracy: 0.5923\n",
      "Epoch 41/50\n",
      "1435/1435 [==============================] - 70s 48ms/step - loss: 1.8183 - accuracy: 0.5932\n",
      "Epoch 42/50\n",
      "1435/1435 [==============================] - 71s 50ms/step - loss: 1.7519 - accuracy: 0.6082\n",
      "Epoch 43/50\n",
      "1435/1435 [==============================] - 71s 50ms/step - loss: 1.7356 - accuracy: 0.6096\n",
      "Epoch 44/50\n",
      "1435/1435 [==============================] - 69s 48ms/step - loss: 1.7084 - accuracy: 0.6180\n",
      "Epoch 45/50\n",
      "1435/1435 [==============================] - 70s 49ms/step - loss: 1.6851 - accuracy: 0.6206\n",
      "Epoch 46/50\n",
      "1435/1435 [==============================] - 68s 47ms/step - loss: 1.6659 - accuracy: 0.6236\n",
      "Epoch 47/50\n",
      "1435/1435 [==============================] - 71s 49ms/step - loss: 1.6322 - accuracy: 0.6289\n",
      "Epoch 48/50\n",
      "1435/1435 [==============================] - 68s 47ms/step - loss: 1.6145 - accuracy: 0.6350\n",
      "Epoch 49/50\n",
      "1435/1435 [==============================] - 67s 47ms/step - loss: 1.6074 - accuracy: 0.6329\n",
      "Epoch 50/50\n",
      "1435/1435 [==============================] - 68s 47ms/step - loss: 1.6181 - accuracy: 0.6305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./tmp/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./tmp/assets\n",
      "2021/01/15 15:34:05 INFO mlflow.tensorflow: Validating the specified TensorFlow model by attempting to load it in a new TensorFlow graph...\n",
      "2021/01/15 15:34:08 INFO mlflow.tensorflow: Validation succeeded!\n",
      "Successfully registered model 'Session Based LSTM Recommender'.\n",
      "2021/01/15 15:34:08 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: Session Based LSTM Recommender, version 1\n",
      "Created version '1' of model 'Session Based LSTM Recommender'.\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run() as parent_run:\n",
    "    for params in grid_search_param:\n",
    "        batch_size = params['batch_size']\n",
    "        window_length = params['window_length']\n",
    "        embedding_dim = params['embedding_dim']\n",
    "        dropout_fc = params['dropout_fc']\n",
    "        hidden_layer_size = params['hidden_layer_size']\n",
    "        n_output_features = params['n_output_features']\n",
    "        n_input_features = params['n_input_features']\n",
    "\n",
    "        with mlflow.start_run(nested=True) as child_run:\n",
    "            # log parameter\n",
    "            mlflow.log_param('batch_size', batch_size)\n",
    "            mlflow.log_param('window_length', window_length)\n",
    "            mlflow.log_param('hidden_layer_size', hidden_layer_size)\n",
    "            mlflow.log_param('dropout_fc_layer', dropout_fc)\n",
    "            mlflow.log_param('embedding_dim', embedding_dim)\n",
    "            mlflow.log_param('n_output_features', n_output_features)\n",
    "            mlflow.log_param('n_unique_input_ids', n_unique_input_ids)\n",
    "            mlflow.log_param('n_input_features', n_input_features)\n",
    "\n",
    "            model = build_lstm_2_layer_model(window_length=window_length,\n",
    "                                             n_output_features=n_output_features,\n",
    "                                             n_unique_input_ids=n_unique_input_ids,\n",
    "                                             n_input_features=n_input_features,\n",
    "                                             embedding_dim=embedding_dim,\n",
    "                                             units_lstm_layer=hidden_layer_size,\n",
    "                                             dropout_rate=dropout_fc)\n",
    "\n",
    "            data = array_to_tf_data_api(sessions_padded,\n",
    "                                        last_clicked,\n",
    "                                        window_length=window_length,\n",
    "                                        batch_size=batch_size)\n",
    "\n",
    "            model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "                          optimizer=keras.optimizers.Nadam(learning_rate=1e-3),\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "            model.fit(data, shuffle=True, initial_epoch=0, epochs=50,\n",
    "                      callbacks=[MlflowLogging()])\n",
    "\n",
    "            model.save(\"./tmp\")\n",
    "\n",
    "            mlflow.tensorflow.log_model(tf_saved_model_dir='./tmp',\n",
    "                                        tf_meta_graph_tags='serve',\n",
    "                                        tf_signature_def_key='serving_default',\n",
    "                                        artifact_path='saved_model',\n",
    "                                        registered_model_name='Session Based LSTM Recommender')\n",
    "\n",
    "            shutil.rmtree(\"./tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
